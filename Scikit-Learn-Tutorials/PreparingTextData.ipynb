{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Text Data for machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding text data in numeric form\n",
    "\n",
    "- One-hot (vector is the size of vocabulary, 1 is present 0 is not, we don't know the number of times a word appears in text)\n",
    "- Frequency-based:\n",
    "    - count\n",
    "    - TF-IDF - term frequency inverse document frequency (take sinto account words that appear often in object and words that apear often dataset such as \"a\", \"an\", \"the\",...)\n",
    "    - co-occurence - similar words will occur together and will have similar context\n",
    "- Prediction-based (based on ml models, word embeddings, dimensionality reduction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag based Models\n",
    "\n",
    "- Bag-of-words: any model that represents a document as a bag of its constituent words, disregarding order but maintaining multiplicity\n",
    "    - count vectorization\n",
    "    - tf-idp vectorization\n",
    "- Bag of n-grams: any model that represents a document as a bag of its constituent n-grams, disregarding order but maintaining multiplicity. words that occur togheter\n",
    "\n",
    "- Not bag of words:\n",
    "    - one hot encoding (no multiplicity)\n",
    "    - word embeddings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [\"The Pessimist Sees Difficulty In Every Opportunity.\",\n",
    "              \"The Optimist Sees Opportunity In Every Difficulty.\",\n",
    "              \"Don’t Let Yesterday Take Up Too Much Of Today. \",\n",
    "              \"You Learn More From Failure Than From Success.\",\n",
    "              \"We May Encounter Many Defeats But We Must Not Be Defeated.\",\n",
    "              \"Life Is Either A Daring Adventure Or Nothing.\"]\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adventure', 'be', 'but', 'daring', 'defeated', 'defeats',\n",
       "       'difficulty', 'don', 'either', 'encounter', 'every', 'failure',\n",
       "       'from', 'in', 'is', 'learn', 'let', 'life', 'many', 'may', 'more',\n",
       "       'much', 'must', 'not', 'nothing', 'of', 'opportunity', 'optimist',\n",
       "       'or', 'pessimist', 'sees', 'success', 'take', 'than', 'the',\n",
       "       'today', 'too', 'up', 'we', 'yesterday', 'you'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 34,\n",
       " 'pessimist': 29,\n",
       " 'sees': 30,\n",
       " 'difficulty': 6,\n",
       " 'in': 13,\n",
       " 'every': 10,\n",
       " 'opportunity': 26,\n",
       " 'optimist': 27,\n",
       " 'don': 7,\n",
       " 'let': 16,\n",
       " 'yesterday': 39,\n",
       " 'take': 32,\n",
       " 'up': 37,\n",
       " 'too': 36,\n",
       " 'much': 21,\n",
       " 'of': 25,\n",
       " 'today': 35,\n",
       " 'you': 40,\n",
       " 'learn': 15,\n",
       " 'more': 20,\n",
       " 'from': 12,\n",
       " 'failure': 11,\n",
       " 'than': 33,\n",
       " 'success': 31,\n",
       " 'we': 38,\n",
       " 'may': 19,\n",
       " 'encounter': 9,\n",
       " 'many': 18,\n",
       " 'defeats': 5,\n",
       " 'but': 2,\n",
       " 'must': 22,\n",
       " 'not': 23,\n",
       " 'be': 1,\n",
       " 'defeated': 4,\n",
       " 'life': 17,\n",
       " 'is': 14,\n",
       " 'either': 8,\n",
       " 'daring': 3,\n",
       " 'adventure': 0,\n",
       " 'or': 28,\n",
       " 'nothing': 24}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get('life')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vector = count_vectorizer.transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 41)\n"
     ]
    }
   ],
   "source": [
    "print(transformer_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0\n",
      "  0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 1 0\n",
      "  0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      "  1 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
      "  0 0 0 0 1]\n",
      " [0 1 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 2 0 0]\n",
      " [1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(transformer_vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['difficulty', 'every', 'in', 'opportunity', 'pessimist', 'sees',\n",
       "        'the'], dtype='<U11'),\n",
       " array(['difficulty', 'every', 'in', 'opportunity', 'optimist', 'sees',\n",
       "        'the'], dtype='<U11'),\n",
       " array(['don', 'let', 'much', 'of', 'take', 'today', 'too', 'up',\n",
       "        'yesterday'], dtype='<U11'),\n",
       " array(['failure', 'from', 'learn', 'more', 'success', 'than', 'you'],\n",
       "       dtype='<U11'),\n",
       " array(['be', 'but', 'defeated', 'defeats', 'encounter', 'many', 'may',\n",
       "        'must', 'not', 'we'], dtype='<U11'),\n",
       " array(['adventure', 'daring', 'either', 'is', 'life', 'nothing', 'or'],\n",
       "       dtype='<U11')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.inverse_transform(transformer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = [\"A room without books is like a body without a soul.\"]\n",
    "count_vectorizer.transform(test_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit(test_text+train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'room': 33,\n",
       " 'without': 44,\n",
       " 'books': 3,\n",
       " 'is': 16,\n",
       " 'like': 20,\n",
       " 'body': 2,\n",
       " 'soul': 35,\n",
       " 'the': 39,\n",
       " 'pessimist': 32,\n",
       " 'sees': 34,\n",
       " 'difficulty': 8,\n",
       " 'in': 15,\n",
       " 'every': 12,\n",
       " 'opportunity': 29,\n",
       " 'optimist': 30,\n",
       " 'don': 9,\n",
       " 'let': 18,\n",
       " 'yesterday': 45,\n",
       " 'take': 37,\n",
       " 'up': 42,\n",
       " 'too': 41,\n",
       " 'much': 24,\n",
       " 'of': 28,\n",
       " 'today': 40,\n",
       " 'you': 46,\n",
       " 'learn': 17,\n",
       " 'more': 23,\n",
       " 'from': 14,\n",
       " 'failure': 13,\n",
       " 'than': 38,\n",
       " 'success': 36,\n",
       " 'we': 43,\n",
       " 'may': 22,\n",
       " 'encounter': 11,\n",
       " 'many': 21,\n",
       " 'defeats': 7,\n",
       " 'but': 4,\n",
       " 'must': 25,\n",
       " 'not': 26,\n",
       " 'be': 1,\n",
       " 'defeated': 6,\n",
       " 'life': 19,\n",
       " 'either': 10,\n",
       " 'daring': 5,\n",
       " 'adventure': 0,\n",
       " 'or': 31,\n",
       " 'nothing': 27}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        2, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.transform(test_text).toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag on n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_vectorizer = CountVectorizer(ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vector = n_gram_vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the pessimist': 35,\n",
       " 'pessimist sees': 29,\n",
       " 'sees difficulty': 30,\n",
       " 'difficulty in': 5,\n",
       " 'in every': 14,\n",
       " 'every opportunity': 10,\n",
       " 'the optimist': 34,\n",
       " 'optimist sees': 27,\n",
       " 'sees opportunity': 31,\n",
       " 'opportunity in': 26,\n",
       " 'every difficulty': 9,\n",
       " 'don let': 6,\n",
       " 'let yesterday': 17,\n",
       " 'yesterday take': 40,\n",
       " 'take up': 32,\n",
       " 'up too': 37,\n",
       " 'too much': 36,\n",
       " 'much of': 22,\n",
       " 'of today': 25,\n",
       " 'you learn': 41,\n",
       " 'learn more': 16,\n",
       " 'more from': 21,\n",
       " 'from failure': 12,\n",
       " 'failure than': 11,\n",
       " 'than from': 33,\n",
       " 'from success': 13,\n",
       " 'we may': 38,\n",
       " 'may encounter': 20,\n",
       " 'encounter many': 8,\n",
       " 'many defeats': 19,\n",
       " 'defeats but': 4,\n",
       " 'but we': 2,\n",
       " 'we must': 39,\n",
       " 'must not': 23,\n",
       " 'not be': 24,\n",
       " 'be defeated': 1,\n",
       " 'life is': 18,\n",
       " 'is either': 15,\n",
       " 'either daring': 7,\n",
       " 'daring adventure': 3,\n",
       " 'adventure or': 0,\n",
       " 'or nothing': 28}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['the pessimist', 'pessimist sees', 'sees difficulty',\n",
       "        'difficulty in', 'in every', 'every opportunity'], dtype='<U17'),\n",
       " array(['in every', 'the optimist', 'optimist sees', 'sees opportunity',\n",
       "        'opportunity in', 'every difficulty'], dtype='<U17'),\n",
       " array(['don let', 'let yesterday', 'yesterday take', 'take up', 'up too',\n",
       "        'too much', 'much of', 'of today'], dtype='<U17'),\n",
       " array(['you learn', 'learn more', 'more from', 'from failure',\n",
       "        'failure than', 'than from', 'from success'], dtype='<U17'),\n",
       " array(['we may', 'may encounter', 'encounter many', 'many defeats',\n",
       "        'defeats but', 'but we', 'we must', 'must not', 'not be',\n",
       "        'be defeated'], dtype='<U17'),\n",
       " array(['life is', 'is either', 'either daring', 'daring adventure',\n",
       "        'adventure or', 'or nothing'], dtype='<U17')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_vectorizer.inverse_transform(transformer_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 68,\n",
       " 'pessimist': 58,\n",
       " 'sees': 60,\n",
       " 'difficulty': 11,\n",
       " 'in': 27,\n",
       " 'every': 19,\n",
       " 'opportunity': 52,\n",
       " 'the pessimist': 70,\n",
       " 'pessimist sees': 59,\n",
       " 'sees difficulty': 61,\n",
       " 'difficulty in': 12,\n",
       " 'in every': 28,\n",
       " 'every opportunity': 21,\n",
       " 'optimist': 54,\n",
       " 'the optimist': 69,\n",
       " 'optimist sees': 55,\n",
       " 'sees opportunity': 62,\n",
       " 'opportunity in': 53,\n",
       " 'every difficulty': 20,\n",
       " 'don': 13,\n",
       " 'let': 33,\n",
       " 'yesterday': 79,\n",
       " 'take': 64,\n",
       " 'up': 74,\n",
       " 'too': 72,\n",
       " 'much': 43,\n",
       " 'of': 50,\n",
       " 'today': 71,\n",
       " 'don let': 14,\n",
       " 'let yesterday': 34,\n",
       " 'yesterday take': 80,\n",
       " 'take up': 65,\n",
       " 'up too': 75,\n",
       " 'too much': 73,\n",
       " 'much of': 44,\n",
       " 'of today': 51,\n",
       " 'you': 81,\n",
       " 'learn': 31,\n",
       " 'more': 41,\n",
       " 'from': 24,\n",
       " 'failure': 22,\n",
       " 'than': 66,\n",
       " 'success': 63,\n",
       " 'you learn': 82,\n",
       " 'learn more': 32,\n",
       " 'more from': 42,\n",
       " 'from failure': 25,\n",
       " 'failure than': 23,\n",
       " 'than from': 67,\n",
       " 'from success': 26,\n",
       " 'we': 76,\n",
       " 'may': 39,\n",
       " 'encounter': 17,\n",
       " 'many': 37,\n",
       " 'defeats': 9,\n",
       " 'but': 4,\n",
       " 'must': 45,\n",
       " 'not': 47,\n",
       " 'be': 2,\n",
       " 'defeated': 8,\n",
       " 'we may': 77,\n",
       " 'may encounter': 40,\n",
       " 'encounter many': 18,\n",
       " 'many defeats': 38,\n",
       " 'defeats but': 10,\n",
       " 'but we': 5,\n",
       " 'we must': 78,\n",
       " 'must not': 46,\n",
       " 'not be': 48,\n",
       " 'be defeated': 3,\n",
       " 'life': 35,\n",
       " 'is': 29,\n",
       " 'either': 15,\n",
       " 'daring': 6,\n",
       " 'adventure': 0,\n",
       " 'or': 56,\n",
       " 'nothing': 49,\n",
       " 'life is': 36,\n",
       " 'is either': 30,\n",
       " 'either daring': 16,\n",
       " 'daring adventure': 7,\n",
       " 'adventure or': 1,\n",
       " 'or nothing': 57}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "transformer_vector = n_gram_vectorizer.fit_transform(train_text)\n",
    "\n",
    "n_gram_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 83)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['the', 'pessimist', 'sees', 'difficulty', 'in', 'every',\n",
       "        'opportunity', 'the pessimist', 'pessimist sees',\n",
       "        'sees difficulty', 'difficulty in', 'in every',\n",
       "        'every opportunity'], dtype='<U17'),\n",
       " array(['the', 'sees', 'difficulty', 'in', 'every', 'opportunity',\n",
       "        'in every', 'optimist', 'the optimist', 'optimist sees',\n",
       "        'sees opportunity', 'opportunity in', 'every difficulty'],\n",
       "       dtype='<U17'),\n",
       " array(['don', 'let', 'yesterday', 'take', 'up', 'too', 'much', 'of',\n",
       "        'today', 'don let', 'let yesterday', 'yesterday take', 'take up',\n",
       "        'up too', 'too much', 'much of', 'of today'], dtype='<U17'),\n",
       " array(['you', 'learn', 'more', 'from', 'failure', 'than', 'success',\n",
       "        'you learn', 'learn more', 'more from', 'from failure',\n",
       "        'failure than', 'than from', 'from success'], dtype='<U17'),\n",
       " array(['we', 'may', 'encounter', 'many', 'defeats', 'but', 'must', 'not',\n",
       "        'be', 'defeated', 'we may', 'may encounter', 'encounter many',\n",
       "        'many defeats', 'defeats but', 'but we', 'we must', 'must not',\n",
       "        'not be', 'be defeated'], dtype='<U17'),\n",
       " array(['life', 'is', 'either', 'daring', 'adventure', 'or', 'nothing',\n",
       "        'life is', 'is either', 'either daring', 'daring adventure',\n",
       "        'adventure or', 'or nothing'], dtype='<U17')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_vectorizer.inverse_transform(transformer_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_vector = tfidf_vectorizer.fit_transform(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 34,\n",
       " 'pessimist': 29,\n",
       " 'sees': 30,\n",
       " 'difficulty': 6,\n",
       " 'in': 13,\n",
       " 'every': 10,\n",
       " 'opportunity': 26,\n",
       " 'optimist': 27,\n",
       " 'don': 7,\n",
       " 'let': 16,\n",
       " 'yesterday': 39,\n",
       " 'take': 32,\n",
       " 'up': 37,\n",
       " 'too': 36,\n",
       " 'much': 21,\n",
       " 'of': 25,\n",
       " 'today': 35,\n",
       " 'you': 40,\n",
       " 'learn': 15,\n",
       " 'more': 20,\n",
       " 'from': 12,\n",
       " 'failure': 11,\n",
       " 'than': 33,\n",
       " 'success': 31,\n",
       " 'we': 38,\n",
       " 'may': 19,\n",
       " 'encounter': 9,\n",
       " 'many': 18,\n",
       " 'defeats': 5,\n",
       " 'but': 2,\n",
       " 'must': 22,\n",
       " 'not': 23,\n",
       " 'be': 1,\n",
       " 'defeated': 4,\n",
       " 'life': 17,\n",
       " 'is': 14,\n",
       " 'either': 8,\n",
       " 'daring': 3,\n",
       " 'adventure': 0,\n",
       " 'or': 28,\n",
       " 'nothing': 24}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.36546139, 0.        , 0.        , 0.        ,\n",
       "        0.36546139, 0.        , 0.        , 0.36546139, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.36546139, 0.        , 0.        , 0.44567684,\n",
       "        0.36546139, 0.        , 0.        , 0.        , 0.36546139,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.36546139, 0.        , 0.        , 0.        ,\n",
       "        0.36546139, 0.        , 0.        , 0.36546139, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.36546139, 0.44567684, 0.        , 0.        ,\n",
       "        0.36546139, 0.        , 0.        , 0.        , 0.36546139,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.33333333, 0.        , 0.        , 0.        ,\n",
       "        0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.33333333, 0.        , 0.        ,\n",
       "        0.33333333, 0.33333333, 0.33333333, 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31622777, 0.63245553, 0.        , 0.        ,\n",
       "        0.31622777, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31622777, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.31622777, 0.        , 0.31622777, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.31622777],\n",
       "       [0.        , 0.2773501 , 0.2773501 , 0.        , 0.2773501 ,\n",
       "        0.2773501 , 0.        , 0.        , 0.        , 0.2773501 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.2773501 , 0.2773501 ,\n",
       "        0.        , 0.        , 0.2773501 , 0.2773501 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.5547002 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.37796447, 0.        , 0.        , 0.37796447, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.        , 0.        , 0.37796447, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.37796447,\n",
       "        0.        , 0.        , 0.        , 0.37796447, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.25276297, 2.25276297, 2.25276297, 2.25276297, 2.25276297,\n",
       "       2.25276297, 1.84729786, 2.25276297, 2.25276297, 2.25276297,\n",
       "       1.84729786, 2.25276297, 2.25276297, 1.84729786, 2.25276297,\n",
       "       2.25276297, 2.25276297, 2.25276297, 2.25276297, 2.25276297,\n",
       "       2.25276297, 2.25276297, 2.25276297, 2.25276297, 2.25276297,\n",
       "       2.25276297, 1.84729786, 2.25276297, 2.25276297, 2.25276297,\n",
       "       1.84729786, 2.25276297, 2.25276297, 2.25276297, 1.84729786,\n",
       "       2.25276297, 2.25276297, 2.25276297, 2.25276297, 2.25276297,\n",
       "       2.25276297])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adventure', 2.252762968495368),\n",
       " ('be', 2.252762968495368),\n",
       " ('but', 2.252762968495368),\n",
       " ('daring', 2.252762968495368),\n",
       " ('defeated', 2.252762968495368),\n",
       " ('defeats', 2.252762968495368),\n",
       " ('difficulty', 1.8472978603872037),\n",
       " ('don', 2.252762968495368),\n",
       " ('either', 2.252762968495368),\n",
       " ('encounter', 2.252762968495368),\n",
       " ('every', 1.8472978603872037),\n",
       " ('failure', 2.252762968495368),\n",
       " ('from', 2.252762968495368),\n",
       " ('in', 1.8472978603872037),\n",
       " ('is', 2.252762968495368),\n",
       " ('learn', 2.252762968495368),\n",
       " ('let', 2.252762968495368),\n",
       " ('life', 2.252762968495368),\n",
       " ('many', 2.252762968495368),\n",
       " ('may', 2.252762968495368),\n",
       " ('more', 2.252762968495368),\n",
       " ('much', 2.252762968495368),\n",
       " ('must', 2.252762968495368),\n",
       " ('not', 2.252762968495368),\n",
       " ('nothing', 2.252762968495368),\n",
       " ('of', 2.252762968495368),\n",
       " ('opportunity', 1.8472978603872037),\n",
       " ('optimist', 2.252762968495368),\n",
       " ('or', 2.252762968495368),\n",
       " ('pessimist', 2.252762968495368),\n",
       " ('sees', 1.8472978603872037),\n",
       " ('success', 2.252762968495368),\n",
       " ('take', 2.252762968495368),\n",
       " ('than', 2.252762968495368),\n",
       " ('the', 1.8472978603872037),\n",
       " ('today', 2.252762968495368),\n",
       " ('too', 2.252762968495368),\n",
       " ('up', 2.252762968495368),\n",
       " ('we', 2.252762968495368),\n",
       " ('yesterday', 2.252762968495368),\n",
       " ('you', 2.252762968495368)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(tfidf_vectorizer.get_feature_names_out(), tfidf_vectorizer.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['opportunity', 'every', 'in', 'difficulty', 'sees', 'pessimist',\n",
       "        'the'], dtype='<U11'),\n",
       " array(['optimist', 'opportunity', 'every', 'in', 'difficulty', 'sees',\n",
       "        'the'], dtype='<U11'),\n",
       " array(['today', 'of', 'much', 'too', 'up', 'take', 'yesterday', 'let',\n",
       "        'don'], dtype='<U11'),\n",
       " array(['success', 'than', 'failure', 'from', 'more', 'learn', 'you'],\n",
       "       dtype='<U11'),\n",
       " array(['defeated', 'be', 'not', 'must', 'but', 'defeats', 'many',\n",
       "        'encounter', 'may', 'we'], dtype='<U11'),\n",
       " array(['nothing', 'or', 'adventure', 'daring', 'either', 'is', 'life'],\n",
       "       dtype='<U11')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.inverse_transform(transformer_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing\n",
    "\n",
    "Can be used to perform dimensionality reduction\n",
    "Hash function maps values into the buckets (lower dimensionality representation)\n",
    "Is a one way operation, is not possible to get the value from the bucket\n",
    "\n",
    "Apply hash function to words to determine their location in the feature vector representing a document. Fast memory efficient but has no inverse transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(n_features=8, norm=None)\n",
    "hash_vector = vectorizer.transform(train_text)\n",
    "hash_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  2.,  1., -1., -1.,  1., -1.,  0.],\n",
       "       [ 0.,  2.,  0., -1., -1.,  1., -1., -1.],\n",
       "       [-1., -1.,  0.,  0.,  2.,  1., -1., -1.],\n",
       "       [ 0.,  0.,  0., -1.,  0.,  0.,  0., -1.],\n",
       "       [ 1.,  1.,  0., -2.,  1.,  1.,  1.,  2.],\n",
       "       [-1.,  0.,  0.,  0.,  1.,  1., -1.,  1.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 1., 1., 1., 1., 1., 0.],\n",
       "       [0., 2., 0., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 0., 0., 2., 1., 3., 1.],\n",
       "       [0., 0., 2., 1., 4., 0., 0., 1.],\n",
       "       [1., 1., 0., 2., 1., 1., 3., 2.],\n",
       "       [1., 2., 0., 0., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(n_features=8, norm=None, alternate_sign=False)\n",
    "hash_vector = vectorizer.transform(train_text)\n",
    "hash_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.28571429,  0.14285714, -0.14285714, -0.14285714,\n",
       "         0.14285714, -0.14285714,  0.        ],\n",
       "       [ 0.        ,  0.28571429,  0.        , -0.14285714, -0.14285714,\n",
       "         0.14285714, -0.14285714, -0.14285714],\n",
       "       [-0.14285714, -0.14285714,  0.        ,  0.        ,  0.28571429,\n",
       "         0.14285714, -0.14285714, -0.14285714],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.5       ,  0.        ,\n",
       "         0.        ,  0.        , -0.5       ],\n",
       "       [ 0.11111111,  0.11111111,  0.        , -0.22222222,  0.11111111,\n",
       "         0.11111111,  0.11111111,  0.22222222],\n",
       "       [-0.2       ,  0.        ,  0.        ,  0.        ,  0.2       ,\n",
       "         0.2       , -0.2       ,  0.2       ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(n_features=8, norm='l1')\n",
    "hash_vector = vectorizer.transform(train_text)\n",
    "hash_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.66666667,  0.33333333, -0.33333333, -0.33333333,\n",
       "         0.33333333, -0.33333333,  0.        ],\n",
       "       [ 0.        ,  0.66666667,  0.        , -0.33333333, -0.33333333,\n",
       "         0.33333333, -0.33333333, -0.33333333],\n",
       "       [-0.33333333, -0.33333333,  0.        ,  0.        ,  0.66666667,\n",
       "         0.33333333, -0.33333333, -0.33333333],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.70710678,  0.        ,\n",
       "         0.        ,  0.        , -0.70710678],\n",
       "       [ 0.2773501 ,  0.2773501 ,  0.        , -0.5547002 ,  0.2773501 ,\n",
       "         0.2773501 ,  0.2773501 ,  0.5547002 ],\n",
       "       [-0.4472136 ,  0.        ,  0.        ,  0.        ,  0.4472136 ,\n",
       "         0.4472136 , -0.4472136 ,  0.4472136 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(n_features=8, norm='l2')\n",
    "hash_vector = vectorizer.transform(train_text)\n",
    "hash_vector.toarray()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = [\n",
    "    {'name': 'Avengers Endgame', 'imdb': 8.8},\n",
    "    {'name':'Inception', 'imdb':8.8},\n",
    "    {'name':'The Wolf of Wall Street', 'imdb':8.2}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vac = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.8, 1. , 0. , 0. ],\n",
       "       [8.8, 0. , 1. , 0. ],\n",
       "       [8.2, 0. , 0. , 1. ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_vector = vac.fit_transform(movie_ratings).toarray()\n",
    "transformer_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['imdb', 'name=Avengers Endgame', 'name=Inception',\n",
       "       'name=The Wolf of Wall Street'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name=Avengers Endgame': 1,\n",
       " 'imdb': 0,\n",
       " 'name=Inception': 2,\n",
       " 'name=The Wolf of Wall Street': 3}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vac.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(transformer_vector, columns=vac.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdb</th>\n",
       "      <th>name=Avengers Endgame</th>\n",
       "      <th>name=Inception</th>\n",
       "      <th>name=The Wolf of Wall Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdb  name=Avengers Endgame  name=Inception  name=The Wolf of Wall Street\n",
       "0   8.8                    1.0             0.0                           0.0\n",
       "1   8.8                    0.0             1.0                           0.0\n",
       "2   8.2                    0.0             0.0                           1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
